import torch
import torch.nn as nn
import numpy as np
import matplotlib.pyplot as plt
import torch.nn.functional as F
from torch.optim import Adam


# Set device
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"Using device: {device}")


# Set random seed for reproducibility
torch.manual_seed(44)
np.random.seed(44)



class VanGenuchten:
    def __init__(self, theta_s, theta_r, alpha, n, Ks, l):
        self.theta_s, self.theta_r = theta_s, theta_r
        self.alpha, self.n, self.m = alpha, n, 1.0 - 1.0/n
        self.Ks, self.l = Ks, l
        self._tiny = 1e-12  # minimal guard

    def theta(self, h):
        abs_h = torch.abs(h)
        denom = (1.0 + (self.alpha * abs_h).pow(self.n)).pow(self.m)
        denom = denom + self._tiny                      # avoid 0
        theta_unsat = self.theta_r + (self.theta_s - self.theta_r) / denom
        return torch.where(h >= 0.0,
                           torch.as_tensor(self.theta_s, device=h.device, dtype=h.dtype),
                           theta_unsat)

    def Se(self, h):
        th = self.theta(h)
        Se = (th - self.theta_r) / (self.theta_s - self.theta_r + self._tiny)
        # keep in (0,1) to avoid fractional-power NaNs
        return torch.clamp(Se, 1e-6, 1.0 - 1e-6)

    def K(self, h):
        Se = self.Se(h)
        Se_1m = Se.pow(1.0 / self.m)
        K_unsat = self.Ks * (Se.pow(self.l)) * (1.0 - (1.0 - Se_1m).pow(self.m)).pow(2)
        return torch.where(h >= 0.0,
                           torch.as_tensor(self.Ks, device=h.device, dtype=h.dtype),
                           torch.clamp(K_unsat, 0.0, self.Ks))  # keep nonnegative & ≤ Ks

class PressureHeadNet(nn.Module):
    """Neural network for pressure head h(z,t)"""
    def __init__(self, hidden_dim, num_layers):
        super().__init__()

        layers = []
        layers.append(nn.Linear(2, hidden_dim))
        layers.append(nn.Tanh())

        for _ in range(num_layers - 1):
            layers.append(nn.Linear(hidden_dim, hidden_dim))
            layers.append(nn.Tanh())

        layers.append(nn.Linear(hidden_dim, 1))

        self.net = nn.Sequential(*layers)

    def forward(self, z, t):
        inputs = torch.cat([z, t], dim=1)
        h = self.net(inputs)
        # Constrain pressure head to reasonable range
        #return torch.clamp(h, -50.0, 5.0)
        return h




class RichardsPINN(nn.Module):
    """PINN for Richards equation with moving boundary"""
    def __init__(self, soil_params, q0_data, Sy, zr, h_net_config, zb_net_config, zb_initial=1.5):
        super().__init__()
        self.h_net = PressureHeadNet(h_net_config['hidden_dim'], h_net_config['num_layers'])
        self.zb_net = WaterTableNet(zb_net_config['hidden_dim'], zb_net_config['num_layers'])
        self.soil = VanGenuchten(**soil_params)
        self.Sy = torch.tensor(Sy, device=device)
        self.zr = zr  # Make this configurable instead of hardcoded 0.5
        self.zb_initial = zb_initial  # Initial water table depth
        self.q0_times = torch.tensor(q0_data[0], dtype=torch.float32, device=device)
        self.q0_values = torch.tensor(q0_data[1], dtype=torch.float32, device=device)

    def forward(self, z, t):
        """Return h(z,t) and z_b(t)"""
        h = self.h_net(z, t)
        zb = self.zb_net(t)
        return h, zb

    def surface_flux(self, t):
        """Prescribed surface flux q0(t) - interpolated from input data"""
        # Interpolate from provided data
        # Simple linear interpolation using torch operations
        t_flat = t.flatten()
        q0_interp = torch.zeros_like(t_flat)
        
        for i in range(len(t_flat)):
            t_val = t_flat[i]
            # Find surrounding points for interpolation
            if t_val <= self.q0_times[0]:
                q0_interp[i] = self.q0_values[0]
            elif t_val >= self.q0_times[-1]:
                q0_interp[i] = self.q0_values[-1]
            else:
                # Linear interpolation
                idx = torch.searchsorted(self.q0_times, t_val)
                if idx == 0:
                    q0_interp[i] = self.q0_values[0]
                else:
                    t1, t2 = self.q0_times[idx-1], self.q0_times[idx]
                    q1, q2 = self.q0_values[idx-1], self.q0_values[idx]
                    alpha = (t_val - t1) / (t2 - t1)
                    q0_interp[i] = q1 + alpha * (q2 - q1)
        
        return q0_interp.reshape_as(t)

# Root uptake can be modified to include more complex root uptake functions
    def root_uptake(self, z, t):
        """Simple root uptake S(z,t) in the root zone"""
        S_max = 1e-7
        return torch.where(z >= -self.zr,
                           torch.full_like(z, S_max),
                           torch.zeros_like(z))

    def compute_derivatives(self, h, z, t):
        """Raw autograd derivatives (no clipping)"""
        theta_h = self.soil.theta(h)
        dtheta_dt = torch.autograd.grad(theta_h.sum(), t, create_graph=True)[0]
        dh_dz     = torch.autograd.grad(h.sum(),       z, create_graph=True)[0]
        K_h       = self.soil.K(h)
        q         = -K_h * (dh_dz + 1.0)
        dq_dz     = torch.autograd.grad(q.sum(),       z, create_graph=True)[0]
        return dtheta_dt, dq_dz, q, K_h

    def pde_residual(self, z, t):
        """Richards equation: ∂θ/∂t = -∂q/∂z - S"""
        z = z.requires_grad_(True)
        t = t.requires_grad_(True)
        h, _ = self(z, t)
        dtheta_dt, dq_dz, _, _ = self.compute_derivatives(h, z, t)
        S = self.root_uptake(z, t)
        return dtheta_dt + dq_dz + S

    def surface_bc_residual(self, t):
        """Flux BC at z=0: q(0,t) = q0(t)"""
        t = t.requires_grad_(True)
        z0 = torch.zeros_like(t, requires_grad=True, device=t.device)
        h0, _ = self(z0, t)
        K0 = self.soil.K(h0)
        dh_dz_0 = torch.autograd.grad(h0.sum(), z0, create_graph=True)[0]
        q_surf = -K0 * (dh_dz_0 + 1.0)
        q0 = self.surface_flux(t)
        return (q_surf - q0)


    def water_table_head_residual(self, t):
            """Head BC at WT: h(-z_b(t), t) = 0"""
            z_dummy = torch.zeros_like(t)
            _, zb = self(z_dummy, t)
            h_wt, _ = self(-zb, t)
            return h_wt


    def initial_conditions_residual(self, z, t0):
        """IC: hydrostatic guess h(z,t0)=z+z_b(t0), and z_b(t0)=zb_initial"""
        h, zb = self(z, t0)
        h_ic = z + zb
        zb_ic = torch.tensor(self.zb_initial, device=z.device).expand_as(zb)
        return (h - h_ic), (zb - zb_ic)

